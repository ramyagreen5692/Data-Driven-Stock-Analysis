{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: 2023-10-03_05-30-00.csv\n",
      "Converted: 2023-10-04_05-30-00.csv\n",
      "Converted: 2023-10-05_05-30-00.csv\n",
      "Converted: 2023-10-06_05-30-00.csv\n",
      "Converted: 2023-10-09_05-30-00.csv\n",
      "Converted: 2023-10-10_05-30-00.csv\n",
      "Converted: 2023-10-11_05-30-00.csv\n",
      "Converted: 2023-10-12_05-30-00.csv\n",
      "Converted: 2023-10-13_05-30-00.csv\n",
      "Converted: 2023-10-16_05-30-00.csv\n",
      "Converted: 2023-10-17_05-30-00.csv\n",
      "Converted: 2023-10-18_05-30-00.csv\n",
      "Converted: 2023-10-19_05-30-00.csv\n",
      "Converted: 2023-10-20_05-30-00.csv\n",
      "Converted: 2023-10-23_05-30-00.csv\n",
      "Converted: 2023-10-25_05-30-00.csv\n",
      "Converted: 2023-10-26_05-30-00.csv\n",
      "Converted: 2023-10-27_05-30-00.csv\n",
      "Converted: 2023-10-30_05-30-00.csv\n",
      "Converted: 2023-10-31_05-30-00.csv\n",
      "Converted: 2023-11-01_05-30-00.csv\n",
      "Converted: 2023-11-02_05-30-00.csv\n",
      "Converted: 2023-11-03_05-30-00.csv\n",
      "Converted: 2023-11-06_05-30-00.csv\n",
      "Converted: 2023-11-07_05-30-00.csv\n",
      "Converted: 2023-11-08_05-30-00.csv\n",
      "Converted: 2023-11-09_05-30-00.csv\n",
      "Converted: 2023-11-10_05-30-00.csv\n",
      "Converted: 2023-11-12_05-30-00.csv\n",
      "Converted: 2023-11-13_05-30-00.csv\n",
      "Converted: 2023-11-15_05-30-00.csv\n",
      "Converted: 2023-11-16_05-30-00.csv\n",
      "Converted: 2023-11-17_05-30-00.csv\n",
      "Converted: 2023-11-20_05-30-00.csv\n",
      "Converted: 2023-11-21_05-30-00.csv\n",
      "Converted: 2023-11-22_05-30-00.csv\n",
      "Converted: 2023-11-23_05-30-00.csv\n",
      "Converted: 2023-11-24_05-30-00.csv\n",
      "Converted: 2023-11-28_05-30-00.csv\n",
      "Converted: 2023-11-29_05-30-00.csv\n",
      "Converted: 2023-11-30_05-30-00.csv\n",
      "Converted: 2023-12-01_05-30-00.csv\n",
      "Converted: 2023-12-04_05-30-00.csv\n",
      "Converted: 2023-12-05_05-30-00.csv\n",
      "Converted: 2023-12-06_05-30-00.csv\n",
      "Converted: 2023-12-07_05-30-00.csv\n",
      "Converted: 2023-12-08_05-30-00.csv\n",
      "Converted: 2023-12-11_05-30-00.csv\n",
      "Converted: 2023-12-12_05-30-00.csv\n",
      "Converted: 2023-12-13_05-30-00.csv\n",
      "Converted: 2023-12-14_05-30-00.csv\n",
      "Converted: 2023-12-15_05-30-00.csv\n",
      "Converted: 2023-12-18_05-30-00.csv\n",
      "Converted: 2023-12-19_05-30-00.csv\n",
      "Converted: 2023-12-20_05-30-00.csv\n",
      "Converted: 2023-12-21_05-30-00.csv\n",
      "Converted: 2023-12-22_05-30-00.csv\n",
      "Converted: 2023-12-26_05-30-00.csv\n",
      "Converted: 2023-12-27_05-30-00.csv\n",
      "Converted: 2023-12-28_05-30-00.csv\n",
      "Converted: 2023-12-29_05-30-00.csv\n",
      "Converted: 2024-01-01_05-30-00.csv\n",
      "Converted: 2024-01-02_05-30-00.csv\n",
      "Converted: 2024-01-03_05-30-00.csv\n",
      "Converted: 2024-01-04_05-30-00.csv\n",
      "Converted: 2024-01-05_05-30-00.csv\n",
      "Converted: 2024-01-08_05-30-00.csv\n",
      "Converted: 2024-01-09_05-30-00.csv\n",
      "Converted: 2024-01-10_05-30-00.csv\n",
      "Converted: 2024-01-11_05-30-00.csv\n",
      "Converted: 2024-01-12_05-30-00.csv\n",
      "Converted: 2024-01-15_05-30-00.csv\n",
      "Converted: 2024-01-16_05-30-00.csv\n",
      "Converted: 2024-01-17_05-30-00.csv\n",
      "Converted: 2024-01-18_05-30-00.csv\n",
      "Converted: 2024-01-19_05-30-00.csv\n",
      "Converted: 2024-01-20_05-30-00.csv\n",
      "Converted: 2024-01-23_05-30-00.csv\n",
      "Converted: 2024-01-24_05-30-00.csv\n",
      "Converted: 2024-01-25_05-30-00.csv\n",
      "Converted: 2024-01-29_05-30-00.csv\n",
      "Converted: 2024-01-30_05-30-00.csv\n",
      "Converted: 2024-01-31_05-30-00.csv\n",
      "Converted: 2024-02-01_05-30-00.csv\n",
      "Converted: 2024-02-02_05-30-00.csv\n",
      "Converted: 2024-02-05_05-30-00.csv\n",
      "Converted: 2024-02-06_05-30-00.csv\n",
      "Converted: 2024-02-07_05-30-00.csv\n",
      "Converted: 2024-02-08_05-30-00.csv\n",
      "Converted: 2024-02-09_05-30-00.csv\n",
      "Converted: 2024-02-12_05-30-00.csv\n",
      "Converted: 2024-02-13_05-30-00.csv\n",
      "Converted: 2024-02-14_05-30-00.csv\n",
      "Converted: 2024-02-15_05-30-00.csv\n",
      "Converted: 2024-02-16_05-30-00.csv\n",
      "Converted: 2024-02-19_05-30-00.csv\n",
      "Converted: 2024-02-20_05-30-00.csv\n",
      "Converted: 2024-02-21_05-30-00.csv\n",
      "Converted: 2024-02-22_05-30-00.csv\n",
      "Converted: 2024-02-23_05-30-00.csv\n",
      "Converted: 2024-02-26_05-30-00.csv\n",
      "Converted: 2024-02-27_05-30-00.csv\n",
      "Converted: 2024-02-28_05-30-00.csv\n",
      "Converted: 2024-02-29_05-30-00.csv\n",
      "Converted: 2024-03-01_05-30-00.csv\n",
      "Converted: 2024-03-02_05-30-00.csv\n",
      "Converted: 2024-03-04_05-30-00.csv\n",
      "Converted: 2024-03-05_05-30-00.csv\n",
      "Converted: 2024-03-06_05-30-00.csv\n",
      "Converted: 2024-03-07_05-30-00.csv\n",
      "Converted: 2024-03-11_05-30-00.csv\n",
      "Converted: 2024-03-12_05-30-00.csv\n",
      "Converted: 2024-03-13_05-30-00.csv\n",
      "Converted: 2024-03-14_05-30-00.csv\n",
      "Converted: 2024-03-15_05-30-00.csv\n",
      "Converted: 2024-03-18_05-30-00.csv\n",
      "Converted: 2024-03-19_05-30-00.csv\n",
      "Converted: 2024-03-20_05-30-00.csv\n",
      "Converted: 2024-03-21_05-30-00.csv\n",
      "Converted: 2024-03-22_05-30-00.csv\n",
      "Converted: 2024-03-26_05-30-00.csv\n",
      "Converted: 2024-03-27_05-30-00.csv\n",
      "Converted: 2024-03-28_05-30-00.csv\n",
      "Converted: 2024-04-01_05-30-00.csv\n",
      "Converted: 2024-04-02_05-30-00.csv\n",
      "Converted: 2024-04-03_05-30-00.csv\n",
      "Converted: 2024-04-04_05-30-00.csv\n",
      "Converted: 2024-04-05_05-30-00.csv\n",
      "Converted: 2024-04-08_05-30-00.csv\n",
      "Converted: 2024-04-09_05-30-00.csv\n",
      "Converted: 2024-04-10_05-30-00.csv\n",
      "Converted: 2024-04-12_05-30-00.csv\n",
      "Converted: 2024-04-15_05-30-00.csv\n",
      "Converted: 2024-04-16_05-30-00.csv\n",
      "Converted: 2024-04-18_05-30-00.csv\n",
      "Converted: 2024-04-19_05-30-00.csv\n",
      "Converted: 2024-04-22_05-30-00.csv\n",
      "Converted: 2024-04-23_05-30-00.csv\n",
      "Converted: 2024-04-24_05-30-00.csv\n",
      "Converted: 2024-04-25_05-30-00.csv\n",
      "Converted: 2024-04-26_05-30-00.csv\n",
      "Converted: 2024-04-29_05-30-00.csv\n",
      "Converted: 2024-04-30_05-30-00.csv\n",
      "Converted: 2024-05-02_05-30-00.csv\n",
      "Converted: 2024-05-03_05-30-00.csv\n",
      "Converted: 2024-05-06_05-30-00.csv\n",
      "Converted: 2024-05-07_05-30-00.csv\n",
      "Converted: 2024-05-08_05-30-00.csv\n",
      "Converted: 2024-05-09_05-30-00.csv\n",
      "Converted: 2024-05-10_05-30-00.csv\n",
      "Converted: 2024-05-13_05-30-00.csv\n",
      "Converted: 2024-05-14_05-30-00.csv\n",
      "Converted: 2024-05-15_05-30-00.csv\n",
      "Converted: 2024-05-16_05-30-00.csv\n",
      "Converted: 2024-05-17_05-30-00.csv\n",
      "Converted: 2024-05-18_05-30-00.csv\n",
      "Converted: 2024-05-21_05-30-00.csv\n",
      "Converted: 2024-05-22_05-30-00.csv\n",
      "Converted: 2024-05-23_05-30-00.csv\n",
      "Converted: 2024-05-24_05-30-00.csv\n",
      "Converted: 2024-05-27_05-30-00.csv\n",
      "Converted: 2024-05-28_05-30-00.csv\n",
      "Converted: 2024-05-29_05-30-00.csv\n",
      "Converted: 2024-05-30_05-30-00.csv\n",
      "Converted: 2024-05-31_05-30-00.csv\n",
      "Converted: 2024-06-03_05-30-00.csv\n",
      "Converted: 2024-06-04_05-30-00.csv\n",
      "Converted: 2024-06-05_05-30-00.csv\n",
      "Converted: 2024-06-06_05-30-00.csv\n",
      "Converted: 2024-06-07_05-30-00.csv\n",
      "Converted: 2024-06-10_05-30-00.csv\n",
      "Converted: 2024-06-11_05-30-00.csv\n",
      "Converted: 2024-06-12_05-30-00.csv\n",
      "Converted: 2024-06-13_05-30-00.csv\n",
      "Converted: 2024-06-14_05-30-00.csv\n",
      "Converted: 2024-06-18_05-30-00.csv\n",
      "Converted: 2024-06-19_05-30-00.csv\n",
      "Converted: 2024-06-20_05-30-00.csv\n",
      "Converted: 2024-06-21_05-30-00.csv\n",
      "Converted: 2024-06-24_05-30-00.csv\n",
      "Converted: 2024-06-25_05-30-00.csv\n",
      "Converted: 2024-06-26_05-30-00.csv\n",
      "Converted: 2024-06-27_05-30-00.csv\n",
      "Converted: 2024-06-28_05-30-00.csv\n",
      "Converted: 2024-07-01_05-30-00.csv\n",
      "Converted: 2024-07-02_05-30-00.csv\n",
      "Converted: 2024-07-03_05-30-00.csv\n",
      "Converted: 2024-07-04_05-30-00.csv\n",
      "Converted: 2024-07-05_05-30-00.csv\n",
      "Converted: 2024-07-08_05-30-00.csv\n",
      "Converted: 2024-07-09_05-30-00.csv\n",
      "Converted: 2024-07-10_05-30-00.csv\n",
      "Converted: 2024-07-11_05-30-00.csv\n",
      "Converted: 2024-07-12_05-30-00.csv\n",
      "Converted: 2024-07-15_05-30-00.csv\n",
      "Converted: 2024-07-16_05-30-00.csv\n",
      "Converted: 2024-07-18_05-30-00.csv\n",
      "Converted: 2024-07-19_05-30-00.csv\n",
      "Converted: 2024-07-22_05-30-00.csv\n",
      "Converted: 2024-07-23_05-30-00.csv\n",
      "Converted: 2024-07-24_05-30-00.csv\n",
      "Converted: 2024-07-25_05-30-00.csv\n",
      "Converted: 2024-07-26_05-30-00.csv\n",
      "Converted: 2024-07-29_05-30-00.csv\n",
      "Converted: 2024-07-30_05-30-00.csv\n",
      "Converted: 2024-07-31_05-30-00.csv\n",
      "Converted: 2024-08-01_05-30-00.csv\n",
      "Converted: 2024-08-02_05-30-00.csv\n",
      "Converted: 2024-08-05_05-30-00.csv\n",
      "Converted: 2024-08-06_05-30-00.csv\n",
      "Converted: 2024-08-07_05-30-00.csv\n",
      "Converted: 2024-08-08_05-30-00.csv\n",
      "Converted: 2024-08-09_05-30-00.csv\n",
      "Converted: 2024-08-12_05-30-00.csv\n",
      "Converted: 2024-08-13_05-30-00.csv\n",
      "Converted: 2024-08-14_05-30-00.csv\n",
      "Converted: 2024-08-16_05-30-00.csv\n",
      "Converted: 2024-08-19_05-30-00.csv\n",
      "Converted: 2024-08-20_05-30-00.csv\n",
      "Converted: 2024-08-21_05-30-00.csv\n",
      "Converted: 2024-08-22_05-30-00.csv\n",
      "Converted: 2024-08-23_05-30-00.csv\n",
      "Converted: 2024-08-26_05-30-00.csv\n",
      "Converted: 2024-08-27_05-30-00.csv\n",
      "Converted: 2024-08-28_05-30-00.csv\n",
      "Converted: 2024-08-29_05-30-00.csv\n",
      "Converted: 2024-08-30_05-30-00.csv\n",
      "Converted: 2024-09-02_05-30-00.csv\n",
      "Converted: 2024-09-03_05-30-00.csv\n",
      "Converted: 2024-09-04_05-30-00.csv\n",
      "Converted: 2024-09-05_05-30-00.csv\n",
      "Converted: 2024-09-06_05-30-00.csv\n",
      "Converted: 2024-09-09_05-30-00.csv\n",
      "Converted: 2024-09-10_05-30-00.csv\n",
      "Converted: 2024-09-11_05-30-00.csv\n",
      "Converted: 2024-09-12_05-30-00.csv\n",
      "Converted: 2024-09-13_05-30-00.csv\n",
      "Converted: 2024-09-16_05-30-00.csv\n",
      "Converted: 2024-09-17_05-30-00.csv\n",
      "Converted: 2024-09-18_05-30-00.csv\n",
      "Converted: 2024-09-19_05-30-00.csv\n",
      "Converted: 2024-09-20_05-30-00.csv\n",
      "Converted: 2024-09-23_05-30-00.csv\n",
      "Converted: 2024-09-24_05-30-00.csv\n",
      "Converted: 2024-09-25_05-30-00.csv\n",
      "Converted: 2024-09-26_05-30-00.csv\n",
      "Converted: 2024-09-27_05-30-00.csv\n",
      "Converted: 2024-09-30_05-30-00.csv\n",
      "Converted: 2024-10-01_05-30-00.csv\n",
      "Converted: 2024-10-03_05-30-00.csv\n",
      "Converted: 2024-10-04_05-30-00.csv\n",
      "Converted: 2024-10-07_05-30-00.csv\n",
      "Converted: 2024-10-08_05-30-00.csv\n",
      "Converted: 2024-10-09_05-30-00.csv\n",
      "Converted: 2024-10-10_05-30-00.csv\n",
      "Converted: 2024-10-11_05-30-00.csv\n",
      "Converted: 2024-10-14_05-30-00.csv\n",
      "Converted: 2024-10-15_05-30-00.csv\n",
      "Converted: 2024-10-16_05-30-00.csv\n",
      "Converted: 2024-10-17_05-30-00.csv\n",
      "Converted: 2024-10-18_05-30-00.csv\n",
      "Converted: 2024-10-21_05-30-00.csv\n",
      "Converted: 2024-10-22_05-30-00.csv\n",
      "Converted: 2024-10-23_05-30-00.csv\n",
      "Converted: 2024-10-24_05-30-00.csv\n",
      "Converted: 2024-10-25_05-30-00.csv\n",
      "Converted: 2024-10-28_05-30-00.csv\n",
      "Converted: 2024-10-29_05-30-00.csv\n",
      "Converted: 2024-10-30_05-30-00.csv\n",
      "Converted: 2024-10-31_05-30-00.csv\n",
      "Converted: 2024-11-01_05-30-00.csv\n",
      "Converted: 2024-11-04_05-30-00.csv\n",
      "Converted: 2024-11-05_05-30-00.csv\n",
      "Converted: 2024-11-06_05-30-00.csv\n",
      "Converted: 2024-11-07_05-30-00.csv\n",
      "Converted: 2024-11-08_05-30-00.csv\n",
      "Converted: 2024-11-11_05-30-00.csv\n",
      "Converted: 2024-11-12_05-30-00.csv\n",
      "Converted: 2024-11-13_05-30-00.csv\n",
      "Converted: 2024-11-14_05-30-00.csv\n",
      "Converted: 2024-11-18_05-30-00.csv\n",
      "Converted: 2024-11-19_05-30-00.csv\n",
      "Converted: 2024-11-21_05-30-00.csv\n",
      "Converted: 2024-11-22_05-30-00.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory where folders like \"10-2023\" are located\n",
    "base_dir = r\"D:\\Stock_Market\"\n",
    "\n",
    "# Loop through each subfolder (e.g., \"10-2023\", \"11-2023\", etc.)\n",
    "for folder_name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    \n",
    "    # Only process directories\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Loop through YAML files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".yaml\"):\n",
    "                yaml_file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                # Read and parse YAML file\n",
    "                with open(yaml_file_path, 'r') as f:\n",
    "                    try:\n",
    "                        data = yaml.safe_load(f)\n",
    "                        if data:  # Only proceed if data is not empty\n",
    "                            df = pd.DataFrame(data)\n",
    "                            \n",
    "                            # Save as CSV with the same name\n",
    "                            csv_file_name = file_name.replace(\".yaml\", \".csv\")\n",
    "                            csv_file_path = os.path.join(folder_path, csv_file_name)\n",
    "                            df.to_csv(csv_file_path, index=False)\n",
    "                            print(f\"Converted: {csv_file_name}\")\n",
    "                        else:\n",
    "                            print(f\"Skipped empty file: {file_name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2023-10\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-17_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-25_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-30_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-10\\2023-10-31_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2023-11\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-17_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-28_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-29_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-11\\2023-11-30_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2023-12\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-28_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2023-12\\2023-12-29_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-01\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-17_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-25_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-29_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-30_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-01\\2024-01-31_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-02\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-28_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-02\\2024-02-29_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-03\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-03\\2024-03-28_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-04\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-25_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-29_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-04\\2024-04-30_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-05\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-17_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-28_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-29_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-30_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-05\\2024-05-31_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-06\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-25_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-06\\2024-06-28_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-07\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-25_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-29_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-30_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-07\\2024-07-31_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-08\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-28_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-29_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-08\\2024-08-30_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-09\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-02_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-17_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-20_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-25_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-26_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-27_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-09\\2024-09-30_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-10\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-03_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-09_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-10_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-15_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-16_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-17_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-22_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-23_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-24_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-25_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-28_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-29_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-30_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-10\\2024-10-31_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\2024-11\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-01_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-04_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-05_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-06_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-07_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-08_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-11_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-12_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-13_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-14_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-18_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-19_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-21_05-30-00.yaml\n",
      "📄 Reading file: D:\\Stock_Market\\2024-11\\2024-11-22_05-30-00.yaml\n",
      "\n",
      "📁 Scanning folder: D:\\Stock_Market\\Symbol_CSVs\n",
      "\n",
      "✅ Total tickers found: 50\n",
      "📊 Sample tickers: ['SBIN', 'BAJFINANCE', 'TITAN', 'ITC', 'TCS']...\n",
      "💾 Saved SBIN.csv with 284 records\n",
      "💾 Saved BAJFINANCE.csv with 284 records\n",
      "💾 Saved TITAN.csv with 284 records\n",
      "💾 Saved ITC.csv with 284 records\n",
      "💾 Saved TCS.csv with 284 records\n",
      "💾 Saved LT.csv with 284 records\n",
      "💾 Saved TATACONSUM.csv with 284 records\n",
      "💾 Saved RELIANCE.csv with 284 records\n",
      "💾 Saved HCLTECH.csv with 284 records\n",
      "💾 Saved JSWSTEEL.csv with 284 records\n",
      "💾 Saved ULTRACEMCO.csv with 284 records\n",
      "💾 Saved POWERGRID.csv with 284 records\n",
      "💾 Saved INFY.csv with 284 records\n",
      "💾 Saved TRENT.csv with 284 records\n",
      "💾 Saved BHARTIARTL.csv with 284 records\n",
      "💾 Saved TATAMOTORS.csv with 284 records\n",
      "💾 Saved WIPRO.csv with 284 records\n",
      "💾 Saved TECHM.csv with 284 records\n",
      "💾 Saved NTPC.csv with 284 records\n",
      "💾 Saved HINDUNILVR.csv with 284 records\n",
      "💾 Saved APOLLOHOSP.csv with 284 records\n",
      "💾 Saved M&M.csv with 284 records\n",
      "💾 Saved GRASIM.csv with 284 records\n",
      "💾 Saved ICICIBANK.csv with 284 records\n",
      "💾 Saved ADANIENT.csv with 284 records\n",
      "💾 Saved ADANIPORTS.csv with 284 records\n",
      "💾 Saved BEL.csv with 284 records\n",
      "💾 Saved BAJAJFINSV.csv with 284 records\n",
      "💾 Saved EICHERMOT.csv with 284 records\n",
      "💾 Saved COALINDIA.csv with 284 records\n",
      "💾 Saved MARUTI.csv with 284 records\n",
      "💾 Saved INDUSINDBK.csv with 284 records\n",
      "💾 Saved ASIANPAINT.csv with 284 records\n",
      "💾 Saved TATASTEEL.csv with 284 records\n",
      "💾 Saved HDFCLIFE.csv with 284 records\n",
      "💾 Saved DRREDDY.csv with 284 records\n",
      "💾 Saved SUNPHARMA.csv with 284 records\n",
      "💾 Saved KOTAKBANK.csv with 284 records\n",
      "💾 Saved SHRIRAMFIN.csv with 284 records\n",
      "💾 Saved NESTLEIND.csv with 284 records\n",
      "💾 Saved ONGC.csv with 284 records\n",
      "💾 Saved CIPLA.csv with 284 records\n",
      "💾 Saved BPCL.csv with 284 records\n",
      "💾 Saved BRITANNIA.csv with 284 records\n",
      "💾 Saved SBILIFE.csv with 284 records\n",
      "💾 Saved HINDALCO.csv with 284 records\n",
      "💾 Saved HEROMOTOCO.csv with 284 records\n",
      "💾 Saved AXISBANK.csv with 284 records\n",
      "💾 Saved HDFCBANK.csv with 284 records\n",
      "💾 Saved BAJAJ-AUTO.csv with 284 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Base directory\n",
    "base_dir = r\"D:\\Stock_Market\"\n",
    "\n",
    "# Dictionary to collect ticker-wise data\n",
    "ticker_data = defaultdict(list)\n",
    "\n",
    "# Loop through each month folder\n",
    "for folder_name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"\\n📁 Scanning folder: {folder_path}\")\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".yaml\"):\n",
    "                yaml_path = os.path.join(folder_path, file_name)\n",
    "                print(f\"📄 Reading file: {yaml_path}\")\n",
    "                with open(yaml_path, 'r') as f:\n",
    "                    try:\n",
    "                        data = yaml.safe_load(f)\n",
    "                        if isinstance(data, list):\n",
    "                            for record in data:\n",
    "                                ticker = record.get(\"Ticker\")\n",
    "                                if ticker:\n",
    "                                    ticker_data[ticker].append(record)\n",
    "                                else:\n",
    "                                    print(f\"⚠️ Missing 'ticker' key in record: {record}\")\n",
    "                        else:\n",
    "                            print(f\"⚠️ Unexpected format in {yaml_path}: {type(data)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Error parsing {yaml_path}: {e}\")\n",
    "\n",
    "# Check how many tickers were found\n",
    "print(f\"\\n✅ Total tickers found: {len(ticker_data)}\")\n",
    "print(f\"📊 Sample tickers: {list(ticker_data.keys())[:5]}{'...' if len(ticker_data) > 5 else ''}\")\n",
    "\n",
    "# Output directory\n",
    "output_dir = os.path.join(base_dir, \"Symbol_CSVs\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save CSV per ticker\n",
    "for ticker, records in ticker_data.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    output_path = os.path.join(output_dir, f\"{ticker}.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"💾 Saved {ticker}.csv with {len(records)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and saved: ADANIENT.csv\n",
      "Cleaned and saved: ADANIPORTS.csv\n",
      "Cleaned and saved: APOLLOHOSP.csv\n",
      "Cleaned and saved: ASIANPAINT.csv\n",
      "Cleaned and saved: AXISBANK.csv\n",
      "Cleaned and saved: BAJAJ-AUTO.csv\n",
      "Cleaned and saved: BAJAJFINSV.csv\n",
      "Cleaned and saved: BAJFINANCE.csv\n",
      "Cleaned and saved: BEL.csv\n",
      "Cleaned and saved: BHARTIARTL.csv\n",
      "Cleaned and saved: BPCL.csv\n",
      "Cleaned and saved: BRITANNIA.csv\n",
      "Cleaned and saved: CIPLA.csv\n",
      "Cleaned and saved: COALINDIA.csv\n",
      "Cleaned and saved: DRREDDY.csv\n",
      "Cleaned and saved: EICHERMOT.csv\n",
      "Cleaned and saved: GRASIM.csv\n",
      "Cleaned and saved: HCLTECH.csv\n",
      "Cleaned and saved: HDFCBANK.csv\n",
      "Cleaned and saved: HDFCLIFE.csv\n",
      "Cleaned and saved: HEROMOTOCO.csv\n",
      "Cleaned and saved: HINDALCO.csv\n",
      "Cleaned and saved: HINDUNILVR.csv\n",
      "Cleaned and saved: ICICIBANK.csv\n",
      "Cleaned and saved: INDUSINDBK.csv\n",
      "Cleaned and saved: INFY.csv\n",
      "Cleaned and saved: ITC.csv\n",
      "Cleaned and saved: JSWSTEEL.csv\n",
      "Cleaned and saved: KOTAKBANK.csv\n",
      "Cleaned and saved: LT.csv\n",
      "Cleaned and saved: M&M.csv\n",
      "Cleaned and saved: MARUTI.csv\n",
      "Cleaned and saved: NESTLEIND.csv\n",
      "Cleaned and saved: NTPC.csv\n",
      "Cleaned and saved: ONGC.csv\n",
      "Cleaned and saved: POWERGRID.csv\n",
      "Cleaned and saved: RELIANCE.csv\n",
      "Cleaned and saved: SBILIFE.csv\n",
      "Cleaned and saved: SBIN.csv\n",
      "Cleaned and saved: SHRIRAMFIN.csv\n",
      "Cleaned and saved: SUNPHARMA.csv\n",
      "Cleaned and saved: TATACONSUM.csv\n",
      "Cleaned and saved: TATAMOTORS.csv\n",
      "Cleaned and saved: TATASTEEL.csv\n",
      "Cleaned and saved: TCS.csv\n",
      "Cleaned and saved: TECHM.csv\n",
      "Cleaned and saved: TITAN.csv\n",
      "Cleaned and saved: TRENT.csv\n",
      "Cleaned and saved: ULTRACEMCO.csv\n",
      "Cleaned and saved: WIPRO.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_folder = \"D:/Stock_Market/symbol_csvs\"\n",
    "output_folder = \"D:/Stock_Market/symbol_csvs_cleaned\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Ensure 'date' is in datetime format\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        # Sort by date\n",
    "        df = df.sort_values('date')\n",
    "\n",
    "        # Drop duplicates\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        # Optional: Reset index\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Save cleaned CSV\n",
    "        cleaned_path = os.path.join(output_folder, filename)\n",
    "        df.to_csv(cleaned_path, index=False)\n",
    "\n",
    "        print(f\"Cleaned and saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Volatility analysis completed and saved at: D:\\Stock_Market\\metrics_csvs\\volatility.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder where symbol-wise CSVs are stored\n",
    "data_folder = r\"D:\\Stock_Market\\symbol_csvs_cleaned\"\n",
    "output_folder = r\"D:\\Stock_Market\\metrics_csvs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "volatility_list = []\n",
    "\n",
    "# Loop through each CSV in the folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        ticker = os.path.splitext(filename)[0]  # Get ticker from filename\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Make sure data is sorted by date\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.sort_values('date', inplace=True)\n",
    "\n",
    "        # Calculate daily returns\n",
    "        df['daily_return'] = df['close'].pct_change()\n",
    "\n",
    "        # Calculate standard deviation (volatility)\n",
    "        volatility = df['daily_return'].std()\n",
    "\n",
    "        # Append to the list\n",
    "        volatility_list.append({'Ticker': ticker, 'Volatility': volatility})\n",
    "\n",
    "# Create a dataframe from the list\n",
    "vol_df = pd.DataFrame(volatility_list)\n",
    "\n",
    "# Sort by Volatility descending\n",
    "vol_df.sort_values(by='Volatility', ascending=False, inplace=True)\n",
    "\n",
    "# Save top 10 most volatile stocks to CSV\n",
    "output_path = os.path.join(output_folder, \"volatility.csv\")\n",
    "vol_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"✅ Volatility analysis completed and saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative returns saved to: D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define input folder and output file path\n",
    "input_folder = r\"D:\\Stock_Market\\symbol_csvs_cleaned\"\n",
    "output_file = r\"D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\"\n",
    "\n",
    "# Create output folder if not exist\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Store cumulative returns for all stocks\n",
    "all_cumulative_returns = []\n",
    "\n",
    "# Process each symbol CSV\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        symbol = filename.replace(\".csv\", \"\")\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Read CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Ensure it's sorted by date\n",
    "        df = df.sort_values(\"date\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        df['daily_return'] = df['close'].pct_change()\n",
    "\n",
    "        # Calculate cumulative return\n",
    "        df['cumulative_return'] = (1 + df['daily_return']).cumprod()\n",
    "\n",
    "        # Add symbol column\n",
    "        df['symbol'] = symbol\n",
    "\n",
    "        # Append relevant columns to final list\n",
    "        all_cumulative_returns.append(df[['date', 'symbol', 'cumulative_return']])\n",
    "\n",
    "# Concatenate all into one DataFrame\n",
    "final_df = pd.concat(all_cumulative_returns, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cumulative returns saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sector-wise performance saved at: D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cumulative returns\n",
    "cumulative_df = pd.read_csv(r\"D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\")\n",
    "\n",
    "# Load sector data\n",
    "sector_df = pd.read_csv(r\"D:\\Stock_Market\\Sector_data - Sheet1.csv\")\n",
    "\n",
    "# Rename columns to match for merging\n",
    "cumulative_df.rename(columns={'symbol': 'ticker'}, inplace=True)\n",
    "sector_df.rename(columns={'Symbol': 'ticker'}, inplace=True)\n",
    "\n",
    "# Merge on 'ticker'\n",
    "merged_df = pd.merge(cumulative_df, sector_df, on='ticker', how='left')\n",
    "\n",
    "# Drop any rows without sector info\n",
    "merged_df.dropna(subset=['sector'], inplace=True)\n",
    "\n",
    "# Group by sector and calculate average cumulative return\n",
    "sector_performance = merged_df.groupby('sector')['cumulative_return'].mean().reset_index()\n",
    "\n",
    "# Sort for better readability\n",
    "sector_performance.sort_values(by='cumulative_return', ascending=False, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\"\n",
    "sector_performance.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"✅ Sector-wise performance saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Correlation matrix saved at: D:\\Stock_Market\\metrics_csvs\\correlation_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Step 1: Load all CSVs and align close prices by date\n",
    "data_dir = r\"D:\\Stock_Market\\symbol_csvs_cleaned\"\n",
    "csv_files = glob(os.path.join(data_dir, \"*.csv\"))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, usecols=['date', 'close'])\n",
    "    ticker = os.path.splitext(os.path.basename(file))[0]\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.rename(columns={'close': ticker})\n",
    "    all_data.append(df.set_index('date'))\n",
    "\n",
    "# Step 2: Merge all close prices into one DataFrame\n",
    "merged_df = pd.concat(all_data, axis=1)\n",
    "merged_df = merged_df.sort_index()\n",
    "\n",
    "# Step 3: Calculate daily percentage change\n",
    "returns_df = merged_df.pct_change().dropna()\n",
    "\n",
    "# Step 4: Calculate correlation matrix\n",
    "correlation_matrix = returns_df.corr()\n",
    "\n",
    "# Step 5: Save correlation matrix\n",
    "output_path = r\"D:\\Stock_Market\\metrics_csvs\\correlation_matrix.csv\"\n",
    "correlation_matrix.to_csv(output_path)\n",
    "\n",
    "print(\"✅ Correlation matrix saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "symbol_folder = Path(\"D:/Stock_Market/symbol_csvs_cleaned\")\n",
    "output_folder = Path(\"D:/Stock_Market/metrics_csvs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "monthly_returns = []\n",
    "\n",
    "# Loop through all stock CSVs\n",
    "for file in symbol_folder.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values('date', inplace=True)\n",
    "    df['month'] = df['date'].dt.to_period('M')\n",
    "    ticker = df['Ticker'].iloc[0]\n",
    "\n",
    "    # Get first and last close of each month\n",
    "    grouped = df.groupby('month').agg(first_close=('close', 'first'), last_close=('close', 'last')).reset_index()\n",
    "    grouped['return'] = (grouped['last_close'] - grouped['first_close']) / grouped['first_close'] * 100\n",
    "    grouped['ticker'] = ticker\n",
    "\n",
    "    monthly_returns.append(grouped)\n",
    "\n",
    "# Combine and save\n",
    "all_monthly_returns_df = pd.concat(monthly_returns, ignore_index=True)\n",
    "all_monthly_returns_df.to_csv(output_folder / \"monthly_returns.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 10 rows successfully.\n",
      "✅ Inserted 20 rows successfully.\n",
      "✅ Inserted 30 rows successfully.\n",
      "✅ Inserted 40 rows successfully.\n",
      "✅ Inserted 50 rows successfully.\n",
      "✅ Volatility data successfully inserted into SQL database!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Database Connection\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"KUjMcLa9iTZrfjU.root\",\n",
    "    password=\"Fd8vm7Rtr3stcucS\",\n",
    "    database=\"Stock\",\n",
    "    ssl_disabled=False  # Required for secure connection\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ✅ Create Table if not exists\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS volatility_analysis (\n",
    "    ticker VARCHAR(10),\n",
    "    volatility FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# ✅ Load the CSV\n",
    "csv_path = r\"D:\\Stock_Market\\metrics_csvs\\volatility.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# ✅ Convert DataFrame to list of tuples\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# ✅ Insert data\n",
    "insert_query = \"INSERT INTO volatility_analysis (ticker, volatility) VALUES (%s, %s)\"\n",
    "\n",
    "batch_size = 10\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, batch)\n",
    "        conn.commit()\n",
    "        print(f\"✅ Inserted {min(i + batch_size, len(data))} rows successfully.\")\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"❌ Error inserting batch {i}-{i + batch_size}: {e}\")\n",
    "\n",
    "# ✅ Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ Volatility data successfully inserted into SQL database!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 500 rows successfully.\n",
      "✅ Inserted 1000 rows successfully.\n",
      "✅ Inserted 1500 rows successfully.\n",
      "✅ Inserted 2000 rows successfully.\n",
      "✅ Inserted 2500 rows successfully.\n",
      "✅ Inserted 3000 rows successfully.\n",
      "✅ Inserted 3500 rows successfully.\n",
      "✅ Inserted 4000 rows successfully.\n",
      "✅ Inserted 4500 rows successfully.\n",
      "✅ Inserted 5000 rows successfully.\n",
      "✅ Inserted 5500 rows successfully.\n",
      "✅ Inserted 6000 rows successfully.\n",
      "✅ Inserted 6500 rows successfully.\n",
      "✅ Inserted 7000 rows successfully.\n",
      "✅ Inserted 7500 rows successfully.\n",
      "✅ Inserted 8000 rows successfully.\n",
      "✅ Inserted 8500 rows successfully.\n",
      "✅ Inserted 9000 rows successfully.\n",
      "✅ Inserted 9500 rows successfully.\n",
      "✅ Inserted 10000 rows successfully.\n",
      "✅ Inserted 10500 rows successfully.\n",
      "✅ Inserted 11000 rows successfully.\n",
      "✅ Inserted 11500 rows successfully.\n",
      "✅ Inserted 12000 rows successfully.\n",
      "✅ Inserted 12500 rows successfully.\n",
      "✅ Inserted 13000 rows successfully.\n",
      "✅ Inserted 13500 rows successfully.\n",
      "✅ Inserted 14000 rows successfully.\n",
      "✅ Inserted 14150 rows successfully.\n",
      "✅ Cumulative returns data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Database Connection\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"KUjMcLa9iTZrfjU.root\",\n",
    "    password=\"Fd8vm7Rtr3stcucS\",\n",
    "    database=\"Stock\",\n",
    "    ssl_disabled=False  # Update this path if necessary\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ✅ Step 1: Create Table for Cumulative Returns\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS cumulative_returns (\n",
    "    date DATE,\n",
    "    ticker VARCHAR(20),\n",
    "    cumulative_return FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# ✅ Step 2: Read CSV File\n",
    "df = pd.read_csv(r\"D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\")\n",
    "\n",
    "# ✅ Step 3: Convert date column to proper format (if needed)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "# ✅ Drop rows with missing values\n",
    "df.dropna(subset=['date', 'symbol', 'cumulative_return'], inplace=True)\n",
    "\n",
    "# ✅ Step 4: Convert DataFrame to List of Tuples\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# ✅ Step 5: Insert in Batches\n",
    "insert_query = \"INSERT INTO cumulative_returns (date, ticker, cumulative_return) VALUES (%s, %s, %s)\"\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, batch)\n",
    "        conn.commit()\n",
    "        print(f\"✅ Inserted {min(i + batch_size, len(data))} rows successfully.\")\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"❌ Error inserting batch {i}-{i + batch_size}: {e}\")\n",
    "\n",
    "# ✅ Step 6: Close Connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ Cumulative returns data inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['average_return']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15700\\190906824.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# ✅ Load the CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# ✅ Drop missing values just in case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'average_return'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# ✅ Convert to list of tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bharanidharan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6669\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6670\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['average_return']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# ✅ Connect to the DB\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"KUjMcLa9iTZrfjU.root\",\n",
    "    password=\"Fd8vm7Rtr3stcucS\",\n",
    "    database=\"Stock\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# ✅ Create table for sector performance\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sector_performance (\n",
    "    sector VARCHAR(50),\n",
    "    average_return FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# ✅ Load the CSV\n",
    "df = pd.read_csv(r\"D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\")\n",
    "\n",
    "# ✅ Drop missing values just in case\n",
    "df.dropna(subset=['sector', 'average_return'], inplace=True)\n",
    "\n",
    "# ✅ Convert to list of tuples\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# ✅ Insert in batches\n",
    "insert_query = \"INSERT INTO sector_performance (sector, average_return) VALUES (%s, %s)\"\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i + batch_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, batch)\n",
    "        conn.commit()\n",
    "        print(f\"✅ Inserted {min(i + batch_size, len(data))} rows successfully.\")\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"❌ Error inserting batch {i}-{i + batch_size}: {e}\")\n",
    "\n",
    "# ✅ Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ Sector performance data inserted successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
