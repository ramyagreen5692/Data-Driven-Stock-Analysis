{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: 2023-10-03_05-30-00.csv\n",
      "Converted: 2023-10-04_05-30-00.csv\n",
      "Converted: 2023-10-05_05-30-00.csv\n",
      "Converted: 2023-10-06_05-30-00.csv\n",
      "Converted: 2023-10-09_05-30-00.csv\n",
      "Converted: 2023-10-10_05-30-00.csv\n",
      "Converted: 2023-10-11_05-30-00.csv\n",
      "Converted: 2023-10-12_05-30-00.csv\n",
      "Converted: 2023-10-13_05-30-00.csv\n",
      "Converted: 2023-10-16_05-30-00.csv\n",
      "Converted: 2023-10-17_05-30-00.csv\n",
      "Converted: 2023-10-18_05-30-00.csv\n",
      "Converted: 2023-10-19_05-30-00.csv\n",
      "Converted: 2023-10-20_05-30-00.csv\n",
      "Converted: 2023-10-23_05-30-00.csv\n",
      "Converted: 2023-10-25_05-30-00.csv\n",
      "Converted: 2023-10-26_05-30-00.csv\n",
      "Converted: 2023-10-27_05-30-00.csv\n",
      "Converted: 2023-10-30_05-30-00.csv\n",
      "Converted: 2023-10-31_05-30-00.csv\n",
      "Converted: 2023-11-01_05-30-00.csv\n",
      "Converted: 2023-11-02_05-30-00.csv\n",
      "Converted: 2023-11-03_05-30-00.csv\n",
      "Converted: 2023-11-06_05-30-00.csv\n",
      "Converted: 2023-11-07_05-30-00.csv\n",
      "Converted: 2023-11-08_05-30-00.csv\n",
      "Converted: 2023-11-09_05-30-00.csv\n",
      "Converted: 2023-11-10_05-30-00.csv\n",
      "Converted: 2023-11-12_05-30-00.csv\n",
      "Converted: 2023-11-13_05-30-00.csv\n",
      "Converted: 2023-11-15_05-30-00.csv\n",
      "Converted: 2023-11-16_05-30-00.csv\n",
      "Converted: 2023-11-17_05-30-00.csv\n",
      "Converted: 2023-11-20_05-30-00.csv\n",
      "Converted: 2023-11-21_05-30-00.csv\n",
      "Converted: 2023-11-22_05-30-00.csv\n",
      "Converted: 2023-11-23_05-30-00.csv\n",
      "Converted: 2023-11-24_05-30-00.csv\n",
      "Converted: 2023-11-28_05-30-00.csv\n",
      "Converted: 2023-11-29_05-30-00.csv\n",
      "Converted: 2023-11-30_05-30-00.csv\n",
      "Converted: 2023-12-01_05-30-00.csv\n",
      "Converted: 2023-12-04_05-30-00.csv\n",
      "Converted: 2023-12-05_05-30-00.csv\n",
      "Converted: 2023-12-06_05-30-00.csv\n",
      "Converted: 2023-12-07_05-30-00.csv\n",
      "Converted: 2023-12-08_05-30-00.csv\n",
      "Converted: 2023-12-11_05-30-00.csv\n",
      "Converted: 2023-12-12_05-30-00.csv\n",
      "Converted: 2023-12-13_05-30-00.csv\n",
      "Converted: 2023-12-14_05-30-00.csv\n",
      "Converted: 2023-12-15_05-30-00.csv\n",
      "Converted: 2023-12-18_05-30-00.csv\n",
      "Converted: 2023-12-19_05-30-00.csv\n",
      "Converted: 2023-12-20_05-30-00.csv\n",
      "Converted: 2023-12-21_05-30-00.csv\n",
      "Converted: 2023-12-22_05-30-00.csv\n",
      "Converted: 2023-12-26_05-30-00.csv\n",
      "Converted: 2023-12-27_05-30-00.csv\n",
      "Converted: 2023-12-28_05-30-00.csv\n",
      "Converted: 2023-12-29_05-30-00.csv\n",
      "Converted: 2024-01-01_05-30-00.csv\n",
      "Converted: 2024-01-02_05-30-00.csv\n",
      "Converted: 2024-01-03_05-30-00.csv\n",
      "Converted: 2024-01-04_05-30-00.csv\n",
      "Converted: 2024-01-05_05-30-00.csv\n",
      "Converted: 2024-01-08_05-30-00.csv\n",
      "Converted: 2024-01-09_05-30-00.csv\n",
      "Converted: 2024-01-10_05-30-00.csv\n",
      "Converted: 2024-01-11_05-30-00.csv\n",
      "Converted: 2024-01-12_05-30-00.csv\n",
      "Converted: 2024-01-15_05-30-00.csv\n",
      "Converted: 2024-01-16_05-30-00.csv\n",
      "Converted: 2024-01-17_05-30-00.csv\n",
      "Converted: 2024-01-18_05-30-00.csv\n",
      "Converted: 2024-01-19_05-30-00.csv\n",
      "Converted: 2024-01-20_05-30-00.csv\n",
      "Converted: 2024-01-23_05-30-00.csv\n",
      "Converted: 2024-01-24_05-30-00.csv\n",
      "Converted: 2024-01-25_05-30-00.csv\n",
      "Converted: 2024-01-29_05-30-00.csv\n",
      "Converted: 2024-01-30_05-30-00.csv\n",
      "Converted: 2024-01-31_05-30-00.csv\n",
      "Converted: 2024-02-01_05-30-00.csv\n",
      "Converted: 2024-02-02_05-30-00.csv\n",
      "Converted: 2024-02-05_05-30-00.csv\n",
      "Converted: 2024-02-06_05-30-00.csv\n",
      "Converted: 2024-02-07_05-30-00.csv\n",
      "Converted: 2024-02-08_05-30-00.csv\n",
      "Converted: 2024-02-09_05-30-00.csv\n",
      "Converted: 2024-02-12_05-30-00.csv\n",
      "Converted: 2024-02-13_05-30-00.csv\n",
      "Converted: 2024-02-14_05-30-00.csv\n",
      "Converted: 2024-02-15_05-30-00.csv\n",
      "Converted: 2024-02-16_05-30-00.csv\n",
      "Converted: 2024-02-19_05-30-00.csv\n",
      "Converted: 2024-02-20_05-30-00.csv\n",
      "Converted: 2024-02-21_05-30-00.csv\n",
      "Converted: 2024-02-22_05-30-00.csv\n",
      "Converted: 2024-02-23_05-30-00.csv\n",
      "Converted: 2024-02-26_05-30-00.csv\n",
      "Converted: 2024-02-27_05-30-00.csv\n",
      "Converted: 2024-02-28_05-30-00.csv\n",
      "Converted: 2024-02-29_05-30-00.csv\n",
      "Converted: 2024-03-01_05-30-00.csv\n",
      "Converted: 2024-03-02_05-30-00.csv\n",
      "Converted: 2024-03-04_05-30-00.csv\n",
      "Converted: 2024-03-05_05-30-00.csv\n",
      "Converted: 2024-03-06_05-30-00.csv\n",
      "Converted: 2024-03-07_05-30-00.csv\n",
      "Converted: 2024-03-11_05-30-00.csv\n",
      "Converted: 2024-03-12_05-30-00.csv\n",
      "Converted: 2024-03-13_05-30-00.csv\n",
      "Converted: 2024-03-14_05-30-00.csv\n",
      "Converted: 2024-03-15_05-30-00.csv\n",
      "Converted: 2024-03-18_05-30-00.csv\n",
      "Converted: 2024-03-19_05-30-00.csv\n",
      "Converted: 2024-03-20_05-30-00.csv\n",
      "Converted: 2024-03-21_05-30-00.csv\n",
      "Converted: 2024-03-22_05-30-00.csv\n",
      "Converted: 2024-03-26_05-30-00.csv\n",
      "Converted: 2024-03-27_05-30-00.csv\n",
      "Converted: 2024-03-28_05-30-00.csv\n",
      "Converted: 2024-04-01_05-30-00.csv\n",
      "Converted: 2024-04-02_05-30-00.csv\n",
      "Converted: 2024-04-03_05-30-00.csv\n",
      "Converted: 2024-04-04_05-30-00.csv\n",
      "Converted: 2024-04-05_05-30-00.csv\n",
      "Converted: 2024-04-08_05-30-00.csv\n",
      "Converted: 2024-04-09_05-30-00.csv\n",
      "Converted: 2024-04-10_05-30-00.csv\n",
      "Converted: 2024-04-12_05-30-00.csv\n",
      "Converted: 2024-04-15_05-30-00.csv\n",
      "Converted: 2024-04-16_05-30-00.csv\n",
      "Converted: 2024-04-18_05-30-00.csv\n",
      "Converted: 2024-04-19_05-30-00.csv\n",
      "Converted: 2024-04-22_05-30-00.csv\n",
      "Converted: 2024-04-23_05-30-00.csv\n",
      "Converted: 2024-04-24_05-30-00.csv\n",
      "Converted: 2024-04-25_05-30-00.csv\n",
      "Converted: 2024-04-26_05-30-00.csv\n",
      "Converted: 2024-04-29_05-30-00.csv\n",
      "Converted: 2024-04-30_05-30-00.csv\n",
      "Converted: 2024-05-02_05-30-00.csv\n",
      "Converted: 2024-05-03_05-30-00.csv\n",
      "Converted: 2024-05-06_05-30-00.csv\n",
      "Converted: 2024-05-07_05-30-00.csv\n",
      "Converted: 2024-05-08_05-30-00.csv\n",
      "Converted: 2024-05-09_05-30-00.csv\n",
      "Converted: 2024-05-10_05-30-00.csv\n",
      "Converted: 2024-05-13_05-30-00.csv\n",
      "Converted: 2024-05-14_05-30-00.csv\n",
      "Converted: 2024-05-15_05-30-00.csv\n",
      "Converted: 2024-05-16_05-30-00.csv\n",
      "Converted: 2024-05-17_05-30-00.csv\n",
      "Converted: 2024-05-18_05-30-00.csv\n",
      "Converted: 2024-05-21_05-30-00.csv\n",
      "Converted: 2024-05-22_05-30-00.csv\n",
      "Converted: 2024-05-23_05-30-00.csv\n",
      "Converted: 2024-05-24_05-30-00.csv\n",
      "Converted: 2024-05-27_05-30-00.csv\n",
      "Converted: 2024-05-28_05-30-00.csv\n",
      "Converted: 2024-05-29_05-30-00.csv\n",
      "Converted: 2024-05-30_05-30-00.csv\n",
      "Converted: 2024-05-31_05-30-00.csv\n",
      "Converted: 2024-06-03_05-30-00.csv\n",
      "Converted: 2024-06-04_05-30-00.csv\n",
      "Converted: 2024-06-05_05-30-00.csv\n",
      "Converted: 2024-06-06_05-30-00.csv\n",
      "Converted: 2024-06-07_05-30-00.csv\n",
      "Converted: 2024-06-10_05-30-00.csv\n",
      "Converted: 2024-06-11_05-30-00.csv\n",
      "Converted: 2024-06-12_05-30-00.csv\n",
      "Converted: 2024-06-13_05-30-00.csv\n",
      "Converted: 2024-06-14_05-30-00.csv\n",
      "Converted: 2024-06-18_05-30-00.csv\n",
      "Converted: 2024-06-19_05-30-00.csv\n",
      "Converted: 2024-06-20_05-30-00.csv\n",
      "Converted: 2024-06-21_05-30-00.csv\n",
      "Converted: 2024-06-24_05-30-00.csv\n",
      "Converted: 2024-06-25_05-30-00.csv\n",
      "Converted: 2024-06-26_05-30-00.csv\n",
      "Converted: 2024-06-27_05-30-00.csv\n",
      "Converted: 2024-06-28_05-30-00.csv\n",
      "Converted: 2024-07-01_05-30-00.csv\n",
      "Converted: 2024-07-02_05-30-00.csv\n",
      "Converted: 2024-07-03_05-30-00.csv\n",
      "Converted: 2024-07-04_05-30-00.csv\n",
      "Converted: 2024-07-05_05-30-00.csv\n",
      "Converted: 2024-07-08_05-30-00.csv\n",
      "Converted: 2024-07-09_05-30-00.csv\n",
      "Converted: 2024-07-10_05-30-00.csv\n",
      "Converted: 2024-07-11_05-30-00.csv\n",
      "Converted: 2024-07-12_05-30-00.csv\n",
      "Converted: 2024-07-15_05-30-00.csv\n",
      "Converted: 2024-07-16_05-30-00.csv\n",
      "Converted: 2024-07-18_05-30-00.csv\n",
      "Converted: 2024-07-19_05-30-00.csv\n",
      "Converted: 2024-07-22_05-30-00.csv\n",
      "Converted: 2024-07-23_05-30-00.csv\n",
      "Converted: 2024-07-24_05-30-00.csv\n",
      "Converted: 2024-07-25_05-30-00.csv\n",
      "Converted: 2024-07-26_05-30-00.csv\n",
      "Converted: 2024-07-29_05-30-00.csv\n",
      "Converted: 2024-07-30_05-30-00.csv\n",
      "Converted: 2024-07-31_05-30-00.csv\n",
      "Converted: 2024-08-01_05-30-00.csv\n",
      "Converted: 2024-08-02_05-30-00.csv\n",
      "Converted: 2024-08-05_05-30-00.csv\n",
      "Converted: 2024-08-06_05-30-00.csv\n",
      "Converted: 2024-08-07_05-30-00.csv\n",
      "Converted: 2024-08-08_05-30-00.csv\n",
      "Converted: 2024-08-09_05-30-00.csv\n",
      "Converted: 2024-08-12_05-30-00.csv\n",
      "Converted: 2024-08-13_05-30-00.csv\n",
      "Converted: 2024-08-14_05-30-00.csv\n",
      "Converted: 2024-08-16_05-30-00.csv\n",
      "Converted: 2024-08-19_05-30-00.csv\n",
      "Converted: 2024-08-20_05-30-00.csv\n",
      "Converted: 2024-08-21_05-30-00.csv\n",
      "Converted: 2024-08-22_05-30-00.csv\n",
      "Converted: 2024-08-23_05-30-00.csv\n",
      "Converted: 2024-08-26_05-30-00.csv\n",
      "Converted: 2024-08-27_05-30-00.csv\n",
      "Converted: 2024-08-28_05-30-00.csv\n",
      "Converted: 2024-08-29_05-30-00.csv\n",
      "Converted: 2024-08-30_05-30-00.csv\n",
      "Converted: 2024-09-02_05-30-00.csv\n",
      "Converted: 2024-09-03_05-30-00.csv\n",
      "Converted: 2024-09-04_05-30-00.csv\n",
      "Converted: 2024-09-05_05-30-00.csv\n",
      "Converted: 2024-09-06_05-30-00.csv\n",
      "Converted: 2024-09-09_05-30-00.csv\n",
      "Converted: 2024-09-10_05-30-00.csv\n",
      "Converted: 2024-09-11_05-30-00.csv\n",
      "Converted: 2024-09-12_05-30-00.csv\n",
      "Converted: 2024-09-13_05-30-00.csv\n",
      "Converted: 2024-09-16_05-30-00.csv\n",
      "Converted: 2024-09-17_05-30-00.csv\n",
      "Converted: 2024-09-18_05-30-00.csv\n",
      "Converted: 2024-09-19_05-30-00.csv\n",
      "Converted: 2024-09-20_05-30-00.csv\n",
      "Converted: 2024-09-23_05-30-00.csv\n",
      "Converted: 2024-09-24_05-30-00.csv\n",
      "Converted: 2024-09-25_05-30-00.csv\n",
      "Converted: 2024-09-26_05-30-00.csv\n",
      "Converted: 2024-09-27_05-30-00.csv\n",
      "Converted: 2024-09-30_05-30-00.csv\n",
      "Converted: 2024-10-01_05-30-00.csv\n",
      "Converted: 2024-10-03_05-30-00.csv\n",
      "Converted: 2024-10-04_05-30-00.csv\n",
      "Converted: 2024-10-07_05-30-00.csv\n",
      "Converted: 2024-10-08_05-30-00.csv\n",
      "Converted: 2024-10-09_05-30-00.csv\n",
      "Converted: 2024-10-10_05-30-00.csv\n",
      "Converted: 2024-10-11_05-30-00.csv\n",
      "Converted: 2024-10-14_05-30-00.csv\n",
      "Converted: 2024-10-15_05-30-00.csv\n",
      "Converted: 2024-10-16_05-30-00.csv\n",
      "Converted: 2024-10-17_05-30-00.csv\n",
      "Converted: 2024-10-18_05-30-00.csv\n",
      "Converted: 2024-10-21_05-30-00.csv\n",
      "Converted: 2024-10-22_05-30-00.csv\n",
      "Converted: 2024-10-23_05-30-00.csv\n",
      "Converted: 2024-10-24_05-30-00.csv\n",
      "Converted: 2024-10-25_05-30-00.csv\n",
      "Converted: 2024-10-28_05-30-00.csv\n",
      "Converted: 2024-10-29_05-30-00.csv\n",
      "Converted: 2024-10-30_05-30-00.csv\n",
      "Converted: 2024-10-31_05-30-00.csv\n",
      "Converted: 2024-11-01_05-30-00.csv\n",
      "Converted: 2024-11-04_05-30-00.csv\n",
      "Converted: 2024-11-05_05-30-00.csv\n",
      "Converted: 2024-11-06_05-30-00.csv\n",
      "Converted: 2024-11-07_05-30-00.csv\n",
      "Converted: 2024-11-08_05-30-00.csv\n",
      "Converted: 2024-11-11_05-30-00.csv\n",
      "Converted: 2024-11-12_05-30-00.csv\n",
      "Converted: 2024-11-13_05-30-00.csv\n",
      "Converted: 2024-11-14_05-30-00.csv\n",
      "Converted: 2024-11-18_05-30-00.csv\n",
      "Converted: 2024-11-19_05-30-00.csv\n",
      "Converted: 2024-11-21_05-30-00.csv\n",
      "Converted: 2024-11-22_05-30-00.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory where folders like \"10-2023\" are located\n",
    "base_dir = r\"D:\\Stock_Market\"\n",
    "\n",
    "# Loop through each subfolder (e.g., \"10-2023\", \"11-2023\", etc.)\n",
    "for folder_name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    \n",
    "    # Only process directories\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Loop through YAML files in the folder\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".yaml\"):\n",
    "                yaml_file_path = os.path.join(folder_path, file_name)\n",
    "                \n",
    "                # Read and parse YAML file\n",
    "                with open(yaml_file_path, 'r') as f:\n",
    "                    try:\n",
    "                        data = yaml.safe_load(f)\n",
    "                        if data:  # Only proceed if data is not empty\n",
    "                            df = pd.DataFrame(data)\n",
    "                            \n",
    "                            # Save as CSV with the same name\n",
    "                            csv_file_name = file_name.replace(\".yaml\", \".csv\")\n",
    "                            csv_file_path = os.path.join(folder_path, csv_file_name)\n",
    "                            df.to_csv(csv_file_path, index=False)\n",
    "                            print(f\"Converted: {csv_file_name}\")\n",
    "                        else:\n",
    "                            print(f\"Skipped empty file: {file_name}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2023-10\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-17_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-25_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-30_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-10\\2023-10-31_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2023-11\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-17_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-28_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-29_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-11\\2023-11-30_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2023-12\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-28_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2023-12\\2023-12-29_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-01\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-17_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-25_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-29_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-30_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-01\\2024-01-31_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-02\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-28_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-02\\2024-02-29_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-03\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-03\\2024-03-28_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-04\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-25_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-29_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-04\\2024-04-30_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-05\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-17_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-28_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-29_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-30_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-05\\2024-05-31_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-06\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-25_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-06\\2024-06-28_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-07\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-25_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-29_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-30_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-07\\2024-07-31_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-08\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-28_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-29_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-08\\2024-08-30_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-09\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-02_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-17_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-20_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-25_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-26_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-27_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-09\\2024-09-30_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-10\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-03_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-09_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-10_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-15_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-16_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-17_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-22_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-23_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-24_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-25_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-28_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-29_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-30_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-10\\2024-10-31_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\2024-11\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-01_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-04_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-05_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-06_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-07_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-08_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-11_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-12_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-13_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-14_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-18_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-19_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-21_05-30-00.yaml\n",
      "ðŸ“„ Reading file: D:\\Stock_Market\\2024-11\\2024-11-22_05-30-00.yaml\n",
      "\n",
      "ðŸ“ Scanning folder: D:\\Stock_Market\\Symbol_CSVs\n",
      "\n",
      "âœ… Total tickers found: 50\n",
      "ðŸ“Š Sample tickers: ['SBIN', 'BAJFINANCE', 'TITAN', 'ITC', 'TCS']...\n",
      "ðŸ’¾ Saved SBIN.csv with 284 records\n",
      "ðŸ’¾ Saved BAJFINANCE.csv with 284 records\n",
      "ðŸ’¾ Saved TITAN.csv with 284 records\n",
      "ðŸ’¾ Saved ITC.csv with 284 records\n",
      "ðŸ’¾ Saved TCS.csv with 284 records\n",
      "ðŸ’¾ Saved LT.csv with 284 records\n",
      "ðŸ’¾ Saved TATACONSUM.csv with 284 records\n",
      "ðŸ’¾ Saved RELIANCE.csv with 284 records\n",
      "ðŸ’¾ Saved HCLTECH.csv with 284 records\n",
      "ðŸ’¾ Saved JSWSTEEL.csv with 284 records\n",
      "ðŸ’¾ Saved ULTRACEMCO.csv with 284 records\n",
      "ðŸ’¾ Saved POWERGRID.csv with 284 records\n",
      "ðŸ’¾ Saved INFY.csv with 284 records\n",
      "ðŸ’¾ Saved TRENT.csv with 284 records\n",
      "ðŸ’¾ Saved BHARTIARTL.csv with 284 records\n",
      "ðŸ’¾ Saved TATAMOTORS.csv with 284 records\n",
      "ðŸ’¾ Saved WIPRO.csv with 284 records\n",
      "ðŸ’¾ Saved TECHM.csv with 284 records\n",
      "ðŸ’¾ Saved NTPC.csv with 284 records\n",
      "ðŸ’¾ Saved HINDUNILVR.csv with 284 records\n",
      "ðŸ’¾ Saved APOLLOHOSP.csv with 284 records\n",
      "ðŸ’¾ Saved M&M.csv with 284 records\n",
      "ðŸ’¾ Saved GRASIM.csv with 284 records\n",
      "ðŸ’¾ Saved ICICIBANK.csv with 284 records\n",
      "ðŸ’¾ Saved ADANIENT.csv with 284 records\n",
      "ðŸ’¾ Saved ADANIPORTS.csv with 284 records\n",
      "ðŸ’¾ Saved BEL.csv with 284 records\n",
      "ðŸ’¾ Saved BAJAJFINSV.csv with 284 records\n",
      "ðŸ’¾ Saved EICHERMOT.csv with 284 records\n",
      "ðŸ’¾ Saved COALINDIA.csv with 284 records\n",
      "ðŸ’¾ Saved MARUTI.csv with 284 records\n",
      "ðŸ’¾ Saved INDUSINDBK.csv with 284 records\n",
      "ðŸ’¾ Saved ASIANPAINT.csv with 284 records\n",
      "ðŸ’¾ Saved TATASTEEL.csv with 284 records\n",
      "ðŸ’¾ Saved HDFCLIFE.csv with 284 records\n",
      "ðŸ’¾ Saved DRREDDY.csv with 284 records\n",
      "ðŸ’¾ Saved SUNPHARMA.csv with 284 records\n",
      "ðŸ’¾ Saved KOTAKBANK.csv with 284 records\n",
      "ðŸ’¾ Saved SHRIRAMFIN.csv with 284 records\n",
      "ðŸ’¾ Saved NESTLEIND.csv with 284 records\n",
      "ðŸ’¾ Saved ONGC.csv with 284 records\n",
      "ðŸ’¾ Saved CIPLA.csv with 284 records\n",
      "ðŸ’¾ Saved BPCL.csv with 284 records\n",
      "ðŸ’¾ Saved BRITANNIA.csv with 284 records\n",
      "ðŸ’¾ Saved SBILIFE.csv with 284 records\n",
      "ðŸ’¾ Saved HINDALCO.csv with 284 records\n",
      "ðŸ’¾ Saved HEROMOTOCO.csv with 284 records\n",
      "ðŸ’¾ Saved AXISBANK.csv with 284 records\n",
      "ðŸ’¾ Saved HDFCBANK.csv with 284 records\n",
      "ðŸ’¾ Saved BAJAJ-AUTO.csv with 284 records\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Base directory\n",
    "base_dir = r\"D:\\Stock_Market\"\n",
    "\n",
    "# Dictionary to collect ticker-wise data\n",
    "ticker_data = defaultdict(list)\n",
    "\n",
    "# Loop through each month folder\n",
    "for folder_name in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, folder_name)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"\\nðŸ“ Scanning folder: {folder_path}\")\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".yaml\"):\n",
    "                yaml_path = os.path.join(folder_path, file_name)\n",
    "                print(f\"ðŸ“„ Reading file: {yaml_path}\")\n",
    "                with open(yaml_path, 'r') as f:\n",
    "                    try:\n",
    "                        data = yaml.safe_load(f)\n",
    "                        if isinstance(data, list):\n",
    "                            for record in data:\n",
    "                                ticker = record.get(\"Ticker\")\n",
    "                                if ticker:\n",
    "                                    ticker_data[ticker].append(record)\n",
    "                                else:\n",
    "                                    print(f\"âš ï¸ Missing 'ticker' key in record: {record}\")\n",
    "                        else:\n",
    "                            print(f\"âš ï¸ Unexpected format in {yaml_path}: {type(data)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Error parsing {yaml_path}: {e}\")\n",
    "\n",
    "# Check how many tickers were found\n",
    "print(f\"\\nâœ… Total tickers found: {len(ticker_data)}\")\n",
    "print(f\"ðŸ“Š Sample tickers: {list(ticker_data.keys())[:5]}{'...' if len(ticker_data) > 5 else ''}\")\n",
    "\n",
    "# Output directory\n",
    "output_dir = os.path.join(base_dir, \"Symbol_CSVs\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save CSV per ticker\n",
    "for ticker, records in ticker_data.items():\n",
    "    df = pd.DataFrame(records)\n",
    "    output_path = os.path.join(output_dir, f\"{ticker}.csv\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"ðŸ’¾ Saved {ticker}.csv with {len(records)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and saved: ADANIENT.csv\n",
      "Cleaned and saved: ADANIPORTS.csv\n",
      "Cleaned and saved: APOLLOHOSP.csv\n",
      "Cleaned and saved: ASIANPAINT.csv\n",
      "Cleaned and saved: AXISBANK.csv\n",
      "Cleaned and saved: BAJAJ-AUTO.csv\n",
      "Cleaned and saved: BAJAJFINSV.csv\n",
      "Cleaned and saved: BAJFINANCE.csv\n",
      "Cleaned and saved: BEL.csv\n",
      "Cleaned and saved: BHARTIARTL.csv\n",
      "Cleaned and saved: BPCL.csv\n",
      "Cleaned and saved: BRITANNIA.csv\n",
      "Cleaned and saved: CIPLA.csv\n",
      "Cleaned and saved: COALINDIA.csv\n",
      "Cleaned and saved: DRREDDY.csv\n",
      "Cleaned and saved: EICHERMOT.csv\n",
      "Cleaned and saved: GRASIM.csv\n",
      "Cleaned and saved: HCLTECH.csv\n",
      "Cleaned and saved: HDFCBANK.csv\n",
      "Cleaned and saved: HDFCLIFE.csv\n",
      "Cleaned and saved: HEROMOTOCO.csv\n",
      "Cleaned and saved: HINDALCO.csv\n",
      "Cleaned and saved: HINDUNILVR.csv\n",
      "Cleaned and saved: ICICIBANK.csv\n",
      "Cleaned and saved: INDUSINDBK.csv\n",
      "Cleaned and saved: INFY.csv\n",
      "Cleaned and saved: ITC.csv\n",
      "Cleaned and saved: JSWSTEEL.csv\n",
      "Cleaned and saved: KOTAKBANK.csv\n",
      "Cleaned and saved: LT.csv\n",
      "Cleaned and saved: M&M.csv\n",
      "Cleaned and saved: MARUTI.csv\n",
      "Cleaned and saved: NESTLEIND.csv\n",
      "Cleaned and saved: NTPC.csv\n",
      "Cleaned and saved: ONGC.csv\n",
      "Cleaned and saved: POWERGRID.csv\n",
      "Cleaned and saved: RELIANCE.csv\n",
      "Cleaned and saved: SBILIFE.csv\n",
      "Cleaned and saved: SBIN.csv\n",
      "Cleaned and saved: SHRIRAMFIN.csv\n",
      "Cleaned and saved: SUNPHARMA.csv\n",
      "Cleaned and saved: TATACONSUM.csv\n",
      "Cleaned and saved: TATAMOTORS.csv\n",
      "Cleaned and saved: TATASTEEL.csv\n",
      "Cleaned and saved: TCS.csv\n",
      "Cleaned and saved: TECHM.csv\n",
      "Cleaned and saved: TITAN.csv\n",
      "Cleaned and saved: TRENT.csv\n",
      "Cleaned and saved: ULTRACEMCO.csv\n",
      "Cleaned and saved: WIPRO.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "input_folder = \"D:/Stock_Market/symbol_csvs\"\n",
    "output_folder = \"D:/Stock_Market/symbol_csvs_cleaned\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Ensure 'date' is in datetime format\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        # Sort by date\n",
    "        df = df.sort_values('date')\n",
    "\n",
    "        # Drop duplicates\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        # Optional: Reset index\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Save cleaned CSV\n",
    "        cleaned_path = os.path.join(output_folder, filename)\n",
    "        df.to_csv(cleaned_path, index=False)\n",
    "\n",
    "        print(f\"Cleaned and saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Volatility analysis completed and saved at: D:\\Stock_Market\\metrics_csvs\\volatility.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder where symbol-wise CSVs are stored\n",
    "data_folder = r\"D:\\Stock_Market\\symbol_csvs_cleaned\"\n",
    "output_folder = r\"D:\\Stock_Market\\metrics_csvs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "volatility_list = []\n",
    "\n",
    "# Loop through each CSV in the folder\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        ticker = os.path.splitext(filename)[0]  # Get ticker from filename\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Make sure data is sorted by date\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.sort_values('date', inplace=True)\n",
    "\n",
    "        # Calculate daily returns\n",
    "        df['daily_return'] = df['close'].pct_change()\n",
    "\n",
    "        # Calculate standard deviation (volatility)\n",
    "        volatility = df['daily_return'].std()\n",
    "\n",
    "        # Append to the list\n",
    "        volatility_list.append({'Ticker': ticker, 'Volatility': volatility})\n",
    "\n",
    "# Create a dataframe from the list\n",
    "vol_df = pd.DataFrame(volatility_list)\n",
    "\n",
    "# Sort by Volatility descending\n",
    "vol_df.sort_values(by='Volatility', ascending=False, inplace=True)\n",
    "\n",
    "# Save top 10 most volatile stocks to CSV\n",
    "output_path = os.path.join(output_folder, \"volatility.csv\")\n",
    "vol_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"âœ… Volatility analysis completed and saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative returns saved to: D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define input folder and output file path\n",
    "input_folder = r\"D:\\Stock_Market\\symbol_csvs_cleaned\"\n",
    "output_file = r\"D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\"\n",
    "\n",
    "# Create output folder if not exist\n",
    "os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "# Store cumulative returns for all stocks\n",
    "all_cumulative_returns = []\n",
    "\n",
    "# Process each symbol CSV\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        symbol = filename.replace(\".csv\", \"\")\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Read CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Ensure it's sorted by date\n",
    "        df = df.sort_values(\"date\")\n",
    "\n",
    "        # Calculate daily returns\n",
    "        df['daily_return'] = df['close'].pct_change()\n",
    "\n",
    "        # Calculate cumulative return\n",
    "        df['cumulative_return'] = (1 + df['daily_return']).cumprod()\n",
    "\n",
    "        # Add symbol column\n",
    "        df['symbol'] = symbol\n",
    "\n",
    "        # Append relevant columns to final list\n",
    "        all_cumulative_returns.append(df[['date', 'symbol', 'cumulative_return']])\n",
    "\n",
    "# Concatenate all into one DataFrame\n",
    "final_df = pd.concat(all_cumulative_returns, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Cumulative returns saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sector-wise performance saved at: D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cumulative returns\n",
    "cumulative_df = pd.read_csv(r\"D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\")\n",
    "\n",
    "# Load sector data\n",
    "sector_df = pd.read_csv(r\"D:\\Stock_Market\\Sector_data - Sheet1.csv\")\n",
    "\n",
    "# Rename columns to match for merging\n",
    "cumulative_df.rename(columns={'symbol': 'ticker'}, inplace=True)\n",
    "sector_df.rename(columns={'Symbol': 'ticker'}, inplace=True)\n",
    "\n",
    "# Merge on 'ticker'\n",
    "merged_df = pd.merge(cumulative_df, sector_df, on='ticker', how='left')\n",
    "\n",
    "# Drop any rows without sector info\n",
    "merged_df.dropna(subset=['sector'], inplace=True)\n",
    "\n",
    "# Group by sector and calculate average cumulative return\n",
    "sector_performance = merged_df.groupby('sector')['cumulative_return'].mean().reset_index()\n",
    "\n",
    "# Sort for better readability\n",
    "sector_performance.sort_values(by='cumulative_return', ascending=False, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\"\n",
    "sector_performance.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"âœ… Sector-wise performance saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Correlation matrix saved at: D:\\Stock_Market\\metrics_csvs\\correlation_matrix.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Step 1: Load all CSVs and align close prices by date\n",
    "data_dir = r\"D:\\Stock_Market\\symbol_csvs_cleaned\"\n",
    "csv_files = glob(os.path.join(data_dir, \"*.csv\"))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file, usecols=['date', 'close'])\n",
    "    ticker = os.path.splitext(os.path.basename(file))[0]\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.rename(columns={'close': ticker})\n",
    "    all_data.append(df.set_index('date'))\n",
    "\n",
    "# Step 2: Merge all close prices into one DataFrame\n",
    "merged_df = pd.concat(all_data, axis=1)\n",
    "merged_df = merged_df.sort_index()\n",
    "\n",
    "# Step 3: Calculate daily percentage change\n",
    "returns_df = merged_df.pct_change().dropna()\n",
    "\n",
    "# Step 4: Calculate correlation matrix\n",
    "correlation_matrix = returns_df.corr()\n",
    "\n",
    "# Step 5: Save correlation matrix\n",
    "output_path = r\"D:\\Stock_Market\\metrics_csvs\\correlation_matrix.csv\"\n",
    "correlation_matrix.to_csv(output_path)\n",
    "\n",
    "print(\"âœ… Correlation matrix saved at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "symbol_folder = Path(\"D:/Stock_Market/symbol_csvs_cleaned\")\n",
    "output_folder = Path(\"D:/Stock_Market/metrics_csvs\")\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "monthly_returns = []\n",
    "\n",
    "# Loop through all stock CSVs\n",
    "for file in symbol_folder.glob(\"*.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values('date', inplace=True)\n",
    "    df['month'] = df['date'].dt.to_period('M')\n",
    "    ticker = df['Ticker'].iloc[0]\n",
    "\n",
    "    # Get first and last close of each month\n",
    "    grouped = df.groupby('month').agg(first_close=('close', 'first'), last_close=('close', 'last')).reset_index()\n",
    "    grouped['return'] = (grouped['last_close'] - grouped['first_close']) / grouped['first_close'] * 100\n",
    "    grouped['ticker'] = ticker\n",
    "\n",
    "    monthly_returns.append(grouped)\n",
    "\n",
    "# Combine and save\n",
    "all_monthly_returns_df = pd.concat(monthly_returns, ignore_index=True)\n",
    "all_monthly_returns_df.to_csv(output_folder / \"monthly_returns.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inserted 10 rows successfully.\n",
      "âœ… Inserted 20 rows successfully.\n",
      "âœ… Inserted 30 rows successfully.\n",
      "âœ… Inserted 40 rows successfully.\n",
      "âœ… Inserted 50 rows successfully.\n",
      "âœ… Volatility data successfully inserted into SQL database!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… Database Connection\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"KUjMcLa9iTZrfjU.root\",\n",
    "    password=\"Fd8vm7Rtr3stcucS\",\n",
    "    database=\"Stock\",\n",
    "    ssl_disabled=False  # Required for secure connection\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# âœ… Create Table if not exists\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS volatility_analysis (\n",
    "    ticker VARCHAR(10),\n",
    "    volatility FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# âœ… Load the CSV\n",
    "csv_path = r\"D:\\Stock_Market\\metrics_csvs\\volatility.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# âœ… Convert DataFrame to list of tuples\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# âœ… Insert data\n",
    "insert_query = \"INSERT INTO volatility_analysis (ticker, volatility) VALUES (%s, %s)\"\n",
    "\n",
    "batch_size = 10\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, batch)\n",
    "        conn.commit()\n",
    "        print(f\"âœ… Inserted {min(i + batch_size, len(data))} rows successfully.\")\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"âŒ Error inserting batch {i}-{i + batch_size}: {e}\")\n",
    "\n",
    "# âœ… Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… Volatility data successfully inserted into SQL database!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Inserted 500 rows successfully.\n",
      "âœ… Inserted 1000 rows successfully.\n",
      "âœ… Inserted 1500 rows successfully.\n",
      "âœ… Inserted 2000 rows successfully.\n",
      "âœ… Inserted 2500 rows successfully.\n",
      "âœ… Inserted 3000 rows successfully.\n",
      "âœ… Inserted 3500 rows successfully.\n",
      "âœ… Inserted 4000 rows successfully.\n",
      "âœ… Inserted 4500 rows successfully.\n",
      "âœ… Inserted 5000 rows successfully.\n",
      "âœ… Inserted 5500 rows successfully.\n",
      "âœ… Inserted 6000 rows successfully.\n",
      "âœ… Inserted 6500 rows successfully.\n",
      "âœ… Inserted 7000 rows successfully.\n",
      "âœ… Inserted 7500 rows successfully.\n",
      "âœ… Inserted 8000 rows successfully.\n",
      "âœ… Inserted 8500 rows successfully.\n",
      "âœ… Inserted 9000 rows successfully.\n",
      "âœ… Inserted 9500 rows successfully.\n",
      "âœ… Inserted 10000 rows successfully.\n",
      "âœ… Inserted 10500 rows successfully.\n",
      "âœ… Inserted 11000 rows successfully.\n",
      "âœ… Inserted 11500 rows successfully.\n",
      "âœ… Inserted 12000 rows successfully.\n",
      "âœ… Inserted 12500 rows successfully.\n",
      "âœ… Inserted 13000 rows successfully.\n",
      "âœ… Inserted 13500 rows successfully.\n",
      "âœ… Inserted 14000 rows successfully.\n",
      "âœ… Inserted 14150 rows successfully.\n",
      "âœ… Cumulative returns data inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# âœ… Database Connection\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"KUjMcLa9iTZrfjU.root\",\n",
    "    password=\"Fd8vm7Rtr3stcucS\",\n",
    "    database=\"Stock\",\n",
    "    ssl_disabled=False  # Update this path if necessary\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# âœ… Step 1: Create Table for Cumulative Returns\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS cumulative_returns (\n",
    "    date DATE,\n",
    "    ticker VARCHAR(20),\n",
    "    cumulative_return FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# âœ… Step 2: Read CSV File\n",
    "df = pd.read_csv(r\"D:\\Stock_Market\\metrics_csvs\\cumulative_returns.csv\")\n",
    "\n",
    "# âœ… Step 3: Convert date column to proper format (if needed)\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "# âœ… Drop rows with missing values\n",
    "df.dropna(subset=['date', 'symbol', 'cumulative_return'], inplace=True)\n",
    "\n",
    "# âœ… Step 4: Convert DataFrame to List of Tuples\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# âœ… Step 5: Insert in Batches\n",
    "insert_query = \"INSERT INTO cumulative_returns (date, ticker, cumulative_return) VALUES (%s, %s, %s)\"\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i+batch_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, batch)\n",
    "        conn.commit()\n",
    "        print(f\"âœ… Inserted {min(i + batch_size, len(data))} rows successfully.\")\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"âŒ Error inserting batch {i}-{i + batch_size}: {e}\")\n",
    "\n",
    "# âœ… Step 6: Close Connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… Cumulative returns data inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['average_return']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15700\\190906824.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# âœ… Load the CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# âœ… Drop missing values just in case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sector'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'average_return'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# âœ… Convert to list of tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bharanidharan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6669\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6670\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['average_return']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# âœ… Connect to the DB\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "    port=4000,\n",
    "    user=\"KUjMcLa9iTZrfjU.root\",\n",
    "    password=\"Fd8vm7Rtr3stcucS\",\n",
    "    database=\"Stock\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# âœ… Create table for sector performance\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sector_performance (\n",
    "    sector VARCHAR(50),\n",
    "    average_return FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "# âœ… Load the CSV\n",
    "df = pd.read_csv(r\"D:\\Stock_Market\\metrics_csvs\\sector_performance.csv\")\n",
    "\n",
    "# âœ… Drop missing values just in case\n",
    "df.dropna(subset=['sector', 'average_return'], inplace=True)\n",
    "\n",
    "# âœ… Convert to list of tuples\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# âœ… Insert in batches\n",
    "insert_query = \"INSERT INTO sector_performance (sector, average_return) VALUES (%s, %s)\"\n",
    "batch_size = 500\n",
    "\n",
    "for i in range(0, len(data), batch_size):\n",
    "    batch = data[i:i + batch_size]\n",
    "    try:\n",
    "        cursor.executemany(insert_query, batch)\n",
    "        conn.commit()\n",
    "        print(f\"âœ… Inserted {min(i + batch_size, len(data))} rows successfully.\")\n",
    "    except mysql.connector.Error as e:\n",
    "        print(f\"âŒ Error inserting batch {i}-{i + batch_size}: {e}\")\n",
    "\n",
    "# âœ… Close connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… Sector performance data inserted successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
